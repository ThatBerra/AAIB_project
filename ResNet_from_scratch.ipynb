{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["F92-KnBBy-lB","xhbvF77EzCxi","9YAHNT9BzFDq"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#GDrive setup"],"metadata":{"id":"_XilKenXG_FS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmnPRRcMFDJ5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","source":["%cd /gdrive/MyDrive/Uni/AAIB/AAIB"],"metadata":{"id":"p1qFGdEkHEvm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Libraries"],"metadata":{"id":"Lo_FtzJHHL7b"}},{"cell_type":"code","source":["!pip install matplotlib==3.1.3"],"metadata":{"id":"_eKNsfnfAQyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install focal-loss"],"metadata":{"id":"zqaZIjYtEwdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","from google.colab import drive\n","import tensorflow as tf\n","import numpy as np\n","\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array,array_to_img\n","from sklearn.metrics import confusion_matrix\n","from keras.callbacks import *\n","import random\n","from keras import backend as K\n","from PIL import Image\n","import cv2\n","import shutil\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)\n","import albumentations as A\n","from itertools import combinations\n","import json\n","from sklearn.utils import class_weight\n","from focal_loss import SparseCategoricalFocalLoss\n","from sklearn.metrics import classification_report\n","from typing import Tuple\n","import scipy\n","from skimage.measure import label as label_fn\n","from skimage import filters\n","import albumentations as A\n","from focal_loss import SparseCategoricalFocalLoss\n","from sklearn.model_selection import StratifiedKFold"],"metadata":{"id":"jdlJ3TbMHK7y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Env Setup"],"metadata":{"id":"DVBCrUzNHfsR"}},{"cell_type":"code","source":["SEED = 4224\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","\n","labels_path = 'data/labels_train_clean.csv'\n","all_data_no_duplicates_path = 'data/train_all_no_duplicates'\n","clean_data_path = 'data/train_clean/'\n","noisy_data_path = 'data/train_noisy/'\n","\n","train_percentage = 0.8\n","validation_percentage = 0.15\n","test_percentage = 0.2\n","img_size = (224,224)\n","batch_size = 16"],"metadata":{"id":"o_jpW8XXHij4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cyclical LR"],"metadata":{"id":"hv4DA41mx6JJ"}},{"cell_type":"code","source":["class CyclicLR(Callback):\n","    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n","    The method cycles the learning rate between two boundaries with\n","    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n","    The amplitude of the cycle can be scaled on a per-iteration or \n","    per-cycle basis.\n","    This class has three built-in policies, as put forth in the paper.\n","    \"triangular\":\n","        A basic triangular cycle w/ no amplitude scaling.\n","    \"triangular2\":\n","        A basic triangular cycle that scales initial amplitude by half each cycle.\n","    \"exp_range\":\n","        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n","        cycle iteration.\n","    For more detail, please see paper.\n","    \n","    # Example\n","        ```python\n","            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n","                                step_size=2000., mode='triangular')\n","            model.fit(X_train, Y_train, callbacks=[clr])\n","        ```\n","    \n","    Class also supports custom scaling functions:\n","        ```python\n","            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n","            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n","                                step_size=2000., scale_fn=clr_fn,\n","                                scale_mode='cycle')\n","            model.fit(X_train, Y_train, callbacks=[clr])\n","        ```    \n","    # Arguments\n","        base_lr: initial learning rate which is the\n","            lower boundary in the cycle.\n","        max_lr: upper boundary in the cycle. Functionally,\n","            it defines the cycle amplitude (max_lr - base_lr).\n","            The lr at any cycle is the sum of base_lr\n","            and some scaling of the amplitude; therefore \n","            max_lr may not actually be reached depending on\n","            scaling function.\n","        step_size: number of training iterations per\n","            half cycle. Authors suggest setting step_size\n","            2-8 x training iterations in epoch.\n","        mode: one of {triangular, triangular2, exp_range}.\n","            Default 'triangular'.\n","            Values correspond to policies detailed above.\n","            If scale_fn is not None, this argument is ignored.\n","        gamma: constant in 'exp_range' scaling function:\n","            gamma**(cycle iterations)\n","        scale_fn: Custom scaling policy defined by a single\n","            argument lambda function, where \n","            0 <= scale_fn(x) <= 1 for all x >= 0.\n","            mode paramater is ignored \n","        scale_mode: {'cycle', 'iterations'}.\n","            Defines whether scale_fn is evaluated on \n","            cycle number or cycle iterations (training\n","            iterations since start of cycle). Default is 'cycle'.\n","    \"\"\"\n","\n","    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n","                 gamma=1., scale_fn=None, scale_mode='cycle'):\n","        super(CyclicLR, self).__init__()\n","\n","        self.base_lr = base_lr\n","        self.max_lr = max_lr\n","        self.step_size = step_size\n","        self.mode = mode\n","        self.gamma = gamma\n","        if scale_fn == None:\n","            if self.mode == 'triangular':\n","                self.scale_fn = lambda x: 1.\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'triangular2':\n","                self.scale_fn = lambda x: 1/(2.**(x-1))\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'exp_range':\n","                self.scale_fn = lambda x: gamma**(x)\n","                self.scale_mode = 'iterations'\n","        else:\n","            self.scale_fn = scale_fn\n","            self.scale_mode = scale_mode\n","        self.clr_iterations = 0.\n","        self.trn_iterations = 0.\n","        self.history = {}\n","        self._reset()\n","\n","    def _reset(self, new_base_lr=None, new_max_lr=None,\n","               new_step_size=None):\n","        \"\"\"Resets cycle iterations.\n","        Optional boundary/step size adjustment.\n","        \"\"\"\n","        if new_base_lr != None:\n","            self.base_lr = new_base_lr\n","        if new_max_lr != None:\n","            self.max_lr = new_max_lr\n","        if new_step_size != None:\n","            self.step_size = new_step_size\n","        self.clr_iterations = 0.\n","        \n","    def clr(self):\n","        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n","        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n","        if self.scale_mode == 'cycle':\n","            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n","        else:\n","            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n","        \n","    def on_train_begin(self, logs={}):\n","        logs = logs or {}\n","\n","        if self.clr_iterations == 0:\n","            K.set_value(self.model.optimizer.lr, self.base_lr)\n","        else:\n","            K.set_value(self.model.optimizer.lr, self.clr())        \n","            \n","    def on_batch_end(self, epoch, logs=None):\n","        \n","        logs = logs or {}\n","        self.trn_iterations += 1\n","        self.clr_iterations += 1\n","\n","        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n","        self.history.setdefault('iterations', []).append(self.trn_iterations)\n","\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","        \n","        K.set_value(self.model.optimizer.lr, self.clr())"],"metadata":{"id":"P3vJGQt-x8cm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Generator"],"metadata":{"id":"_q6PyNykH4T7"}},{"cell_type":"code","source":["class CustomGenerator(tf.keras.utils.Sequence):\n","  \"\"\"\n","    CustomGenerator inheriting from tf.keras.utils.Sequence.\n","\n","    We have to implement 3 main methods:\n","      - __init__: save dataset params like directory, filenames, etc.\n","      - __len__: return the total number of samples in the dataset (number of batches)\n","      - __getitem__: return a single batch of paired images masks\n","  \"\"\"\n","\n","  def __init__(self, \n","               dataframe, # dataframe of the dataset  \n","               base_path,\n","               preprocessing_function=None, # Preprocessing function (e.g., the one used for transfer learning)\n","               batch_size=16, # Batch size\n","               out_shape = (100,100),\n","               shuffle=False,\n","               categorical = True,\n","               augment = False,\n","               seed = SEED,\n","               flow_from_directory = True,\n","               preprocess_input = False):\n","    \n","    # Get all filenames\n","    if isinstance(base_path, Tuple):\n","      self.filenames = []\n","      for p in base_path:\n","\n","        paths = self.folderToPaths(p, full_path = False)\n","\n","        for pa in paths:\n","          if pa in set(dataframe.file):\n","            self.filenames.append(os.path.join(p, pa))\n","\n","\n","    else:\n","        self.filenames = [os.path.join(base_path, img_path) for img_path in list(dataframe.file)]\n","\n","    self.labels = tfk.utils.to_categorical(list(dataframe.label)) if categorical else list(dataframe.label)\n","\n","    # Set indices list in [0, len(subset_filenames)]\n","    self.indices = np.arange(len(self.filenames))\n","\n","    # Save dataset parameters as class attributes\n","    self.base_path = base_path\n","    self.preprocessing_function = preprocessing_function\n","    self.out_shape = out_shape\n","    self.batch_size = batch_size\n","    self.shuffle = shuffle\n","    self.augment = augment\n","    self.seed = seed\n","    self.flow_from_directory =flow_from_directory\n","    self.data_augmentation = A.Compose([\n","    A.RandomBrightnessContrast(brightness_limit = 0.05, contrast_limit=0.05, p=0.5),\n","    A.ShiftScaleRotate(p = 0.8, rotate_limit = 20, scale_limit = 0.3, border_mode =  cv2.BORDER_CONSTANT, value = 0),\n","    A.CLAHE(p=0.2)\n","    ])\n","    self.preprocess_input = preprocess_input\n","\n","    if not self.flow_from_directory:\n","      self.images = self.load_all_imgs()\n","\n","  def augmentation(self, images):\n","    return self.data_augmentation(image = images)\n","\n","\n","  def __filterNoisyOnClahe(self, image):\n","    clahe = cv2.createCLAHE(clipLimit = 300, tileGridSize = (50, 50))\n","    im1 = cv2.resize(image, (400, 400))\n","    im1 = scipy.ndimage.gaussian_laplace(im1, sigma = 6)\n","    im1 = clahe.apply(im1)\n","    var1 = np.var(im1)\n","    if var1 > 800:\n","      image= cv2.medianBlur(image, ksize=5)\n","      return scipy.ndimage.uniform_filter(image, size=3)\n","    else:\n","      return image\n","\n","\n","  def __sharpenImage(self, image):\n","    sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n","\n","    sharpened = cv2.filter2D(image, -1, sharpen_kernel)\n","\n","    return sharpened\n","\n","  def __invert_image(self, img):\n","\n","    otsu_thresh = filters.threshold_otsu(img)\n","    masked_image = (img > otsu_thresh) * 1.0\n","    valsROI1, _ = np.histogram(masked_image[220:244, 220:244], bins=2, range=(0, 1))\n","    valsROI2, _ = np.histogram(masked_image[0:25, 0:25], bins=2, range=(0, 1))\n","    valsROI3, _ = np.histogram(masked_image[0:25, 220:244], bins=2, range=(0, 1))\n","    valsROI4, _ = np.histogram(masked_image[220:244, 0:25], bins=2, range=(0, 1))\n","    \n","    valsTot = valsROI1 + valsROI2 + valsROI3 + valsROI4\n","    \n","    labels = label_fn(masked_image)\n","\n","    if len(np.unique(labels)) < 100:\n","        if valsTot[0] > valsTot[1]:\n","            return img\n","        else:\n","            return 255 - img\n","    return img\n","\n","  def __filterBlurred(self, image):\n","    clahe = cv2.createCLAHE(clipLimit = 1.8, tileGridSize = (4, 4))\n","    minThresh = 2\n","    im1 = cv2.resize(image, (400, 400))\n","    im1 = scipy.ndimage.gaussian_laplace(im1, sigma = 2)\n","    im1 = clahe.apply(im1)\n","    _, im1 = cv2.threshold(im1, minThresh, 255, cv2.THRESH_BINARY)\n","    var1 = np.var(im1)\n","    if var1 < 5:\n","        return self.__sharpenImage(image)\n","    else:\n","        return self.__sharpenImage(image)\n","\n","  def __filterUnderexposed(self, image):\n","    im1 = cv2.resize(image, (400, 400))\n","    mean1 = np.mean(im1)\n","    if mean1 < 71:\n","      clahe = cv2.createCLAHE(clipLimit = 2, tileGridSize = (2, 2))\n","      image = clahe.apply(image)\n","      return image\n","    else:\n","      return image\n","\n","\n","  def preprocess(self, image):\n","\n","    image = self.__invert_image(image)\n","    image = self.__filterUnderexposed(image)\n","    image = self.__filterNoisyOnClahe(image)\n","    image = self.__filterBlurred(image)\n","   \n","\n","    return image\n","\n","  def __len__(self):\n","    # Return the length of the dataset (number of batches)\n","    # that is given by #images // batch_size\n","    return len(self.filenames) // self.batch_size\n","\n","  def on_epoch_start(self):\n","    # Shuffle indices after each epoch\n","    if self.shuffle == True:\n","        np.random.shuffle(self.indices)\n","\n","  def load_all_imgs(self):\n","      images = []\n","      for f in self.filenames:\n","        image = cv2.imread(f, 0)\n","        image = cv2.resize(image, (self.out_shape))\n","        if self.preprocess_input:\n","          image = self.preprocess(image)\n","        images.append(image)\n","\n","      return np.array(images)\n","\n","  def get_image_and_label(self, index):\n","\n","    if not self.flow_from_directory:\n","      image = self.images[index]\n","      if self.augment:\n","        image = self.augmentation(image)\n","      image = np.squeeze(image)\n","      curr_label = self.labels[index]\n","    else:\n","      curr_filename = self.filenames[index] # Get filename at index\n","      curr_label = self.labels[index]\n","      image = cv2.imread(curr_filename, 0)\n","      image = cv2.resize(image, (self.out_shape))\n","      if self.preprocess_input:\n","        image = self.preprocess(image)\n","\n","      if self.augment:\n","        image = self.augmentation(image)['image']\n","\n","\n","\n","    return image, curr_label\n","\n","  def __getitem__(self, index):\n","    # In this function we generate a batch (of size self.batch_size) of images and corresponding masks\n","    \n","    # Get 'self.batch_size' indices\n","    current_indices = self.indices[index*self.batch_size:(index*self.batch_size)+self.batch_size]\n","\n","    \"\"\"if len(current_indices) == 0:\n","      current_indices = self.indices[len(self.indices)-self.batch_size:len(self.indices)]\"\"\"\n","\n","    # Init lists that will contain images and masks\n","    batch_images = []\n","    batch_labels = []\n","\n","    # Cycle over the indices\n","    for idx in current_indices:\n","      # Get single image/mask at index 'idx'\n","      image, label = self.get_image_and_label(idx)\n","\n","      # Apply the preprocessing function\n","      if self.preprocessing_function is not None:\n","        image = self.preprocessing_function(image)\n","\n","      # Append both image and mask (with added batch dimension) to the corresponding batch lists\n","      batch_images.append(np.expand_dims(image, 0))\n","      batch_labels.append(label)\n","     \n","    # Finally, obtain a final batch by concatenating all the images over the batch dimension\n","    batch_images = np.concatenate(batch_images, axis=0)\n","    batch_labels = np.array(batch_labels)\n","\n","    return batch_images, batch_labels\n","\n","\n","  def folderToPaths(\n","        self,\n","        full_img_dir,\n","        full_path = True\n","):\n","\n","    x_paths_list = []\n","\n","    full_img_dir = full_img_dir\n","\n","    for full in os.listdir(full_img_dir):\n","         if full_path:\n","            x_paths_list.append(os.path.join(full_img_dir, full))\n","         else:\n","          x_paths_list.append(full)\n","    \n","    x_paths_list.sort()\n","    return x_paths_list"],"metadata":{"id":"5gN3Wfn4G9fN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Loading"],"metadata":{"id":"3pqta_PMH0WD"}},{"cell_type":"code","source":["def encode(x):\n","  if x == 'N':\n","    return 0\n","  elif x == 'P':\n","    return 1\n","  else:\n","    return 2"],"metadata":{"id":"nrjZND-MH2ej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def folderToPaths(\n","        full_img_dir,\n","        full_path = True\n","):\n","\n","    x_paths_list = []\n","\n","    full_img_dir = full_img_dir\n","\n","    for full in os.listdir(full_img_dir):\n","         if full_path:\n","            x_paths_list.append(os.path.join(full_img_dir, full))\n","         else:\n","          x_paths_list.append(full)\n","    \n","    x_paths_list.sort()\n","    return x_paths_list"],"metadata":{"id":"J6ryz0xKH-H1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labelsDF = pd.read_csv(labels_path)\n","display(labelsDF.head(20))"],"metadata":{"id":"lr43Gr7_5DLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labelsDF.label = labelsDF.label.apply(lambda x: encode(x))\n","display(labelsDF.head(20))"],"metadata":{"id":"k1i7v3gM5Fq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_data_no_duplicates_path_list = folderToPaths(full_img_dir = all_data_no_duplicates_path)"],"metadata":{"id":"BXJPaY5-IPUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_val, test = train_test_split(labelsDF, test_size = test_percentage, shuffle = True, stratify = labelsDF.label)\n","train, val = train_test_split(train_val, test_size = validation_percentage, shuffle = True, stratify = train_val.label)"],"metadata":{"id":"oYdWBa2oIlIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_gen = CustomGenerator(dataframe = train, base_path = 'data/train_all_no_duplicates', batch_size = batch_size, out_shape = img_size, shuffle = True, categorical=False, flow_from_directory=False, preprocess_input = True)\n","valid_gen = CustomGenerator(dataframe = val, base_path = 'data/train_all_no_duplicates', batch_size = batch_size, out_shape = img_size, shuffle = True, categorical=False, flow_from_directory=False, preprocess_input = True)\n","test_gen = CustomGenerator(dataframe = test, base_path = 'data/train_all_no_duplicates', batch_size = batch_size, out_shape = img_size, shuffle = True, categorical=False, flow_from_directory=False, preprocess_input = True)"],"metadata":{"id":"H-lILpY3I4jL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_labels = np.array(list(set(labelsDF.label)), dtype=int)"],"metadata":{"id":"t_jDDSkvJAY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_weights = class_weight.compute_class_weight('balanced',\n","                                                 classes = dataset_labels,\n","                                                 y = train.label)\n","class_weights"],"metadata":{"id":"1YPclO0YvNZo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Residual Network developed from scratch"],"metadata":{"id":"cwAxsWD8vPkz"}},{"cell_type":"markdown","source":["##Model Definition"],"metadata":{"id":"F92-KnBBy-lB"}},{"cell_type":"code","source":["from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, concatenate, BatchNormalization, Reshape\n","from keras.layers import Dense, Flatten, GlobalAveragePooling2D, MaxPooling2D, BatchNormalization,Concatenate, Resizing\n","from keras import regularizers"],"metadata":{"id":"t4rHuIYUaBei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ResBs_Conv(block_input, num_filters): \n","   \n","    # 0. Filter Block input and BatchNormalization\n","    block_input = Conv2D(num_filters, kernel_size=7, strides=2,  padding='same')(block_input) \n","    block_input = BatchNormalization()(block_input)\n","\n","    # 1. First Convolutional Layer\n","    conv1 = Conv2D(filters=num_filters, kernel_size=7, padding='same')(block_input)\n","    norm1 = BatchNormalization()(conv1)\n","    relu1 = Activation('relu')(norm1)  \n","    dropout = Dropout(0.2)(relu1)\n","    \n","    # 2. Second Convolutional Layer \n","    conv2 = Conv2D(num_filters, kernel_size=7, padding='same')(dropout)\n","    norm2 = BatchNormalization()(conv2)\n","\n","    # 3. Summing Layer (adding a residual connection)\n","    sum = Add()([block_input, norm2])\n","    \n","    # 4. Activation Layer\n","    relu2 = Activation('relu')(sum)\n","    \n","    return relu2 "],"metadata":{"id":"DHCLXE8is68N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ResBs_Identity(block_input, num_filters): \n","\n","    # 1. First Convolutional Layer\n","    conv1 = Conv2D(filters=num_filters, kernel_size=7, padding= 'same')(block_input)\n","    norm1 = BatchNormalization()(conv1)\n","    relu1 = Activation('relu')(norm1)    \n","    dropout = Dropout(0.2)(relu1)\n","    \n","    # 2. Second Convolutional Layer \n","    conv2 = Conv2D(num_filters, kernel_size=7, padding= 'same')(dropout)\n","    norm2 = BatchNormalization()(conv2)\n","\n","    # 3. Summing Layer (adding a residual connection)\n","    sum = Add()([block_input, norm2])\n","    \n","    # 4. Activation Layer\n","    relu2 = Activation('relu')(sum)\n","    \n","    return relu2 "],"metadata":{"id":"HGHV32jys2QG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_model(input_shape, N):\n","  inputs = tfk.Input(shape=input_shape)\n","  \n","  conv1 = tfkl.Conv2D(\n","          filters=32,\n","          kernel_size=3,\n","          padding = 'same',\n","          activation = 'relu',\n","          kernel_initializer = tfk.initializers.HeUniform(SEED)\n","      )(inputs)\n","  bn1 = tfkl.BatchNormalization()(conv1) \n","  relu1 = Activation('relu')(bn1) \n","  pool1 = MaxPooling2D()(relu1)\n","\n","\n","  #left side\n","  conv2_1 = tfkl.Conv2D(\n","          filters=64,\n","          kernel_size=3,\n","          padding = 'same',\n","          activation = 'relu',\n","          kernel_initializer = tfk.initializers.HeUniform(SEED)\n","      )(pool1)\n","  bn2_1 = BatchNormalization()(conv2_1)\n","  relu2 = Activation('relu')(bn2_1) \n","\n","  conv2_1 = tfkl.Conv2D(\n","          filters=64,\n","          kernel_size=3,\n","          padding = 'same',\n","          activation = 'relu',\n","          kernel_initializer = tfk.initializers.HeUniform(SEED)\n","      )(relu2)\n","  bn2_1 = BatchNormalization()(conv2_1)\n","  relu2 = Activation('relu')(bn2_1) \n","\n","  conv2_1 = tfkl.Conv2D(\n","          filters=64,\n","          kernel_size=3,\n","          padding = 'same',\n","          activation = 'relu',\n","          kernel_initializer = tfk.initializers.HeUniform(SEED)\n","      )(relu2)\n","  bn2_1 = BatchNormalization()(conv2_1)  \n","\n","  bn2_1 = tfkl.Dropout(0.2, seed=SEED)(bn2_1)\n","\n","  #right side\n","  conv2_2 = tfkl.Conv2D(\n","          filters=64,\n","          kernel_size=3,\n","          padding = 'same',\n","          activation = 'relu',\n","          kernel_initializer = tfk.initializers.HeUniform(SEED)\n","      )(pool1)\n","  bn2_2 = BatchNormalization()(conv2_2)\n","\n","  bn2_2 = tfkl.Dropout(0.3, seed=SEED)(bn2_2)\n","\n","  #addition\n","  sum = Add()([bn2_1, bn2_2])\n","  relu = Activation('relu')(sum)\n","\n","  ResNet = tfkl.Dropout(0.2, seed=SEED)(relu)\n","\n","  filters=64\n","  '''we also tried\n","  filters=32'''\n","  \n","  M = int((N - 2)/2)\n","  for i in range(M): \n","    filters = filters * 2\n","    # define N-th ResBs block\n","    ResNet = ResBs_Conv(ResNet, filters)\n","    ResNet = ResBs_Identity(ResNet, filters)\n","    \n","  y = tf.keras.layers.GlobalAveragePooling2D()(ResNet)\n","\n","  y = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tfk.initializers.HeUniform(SEED))(y)\n","  y = tfkl.Dropout(0.1, seed=SEED)(y)\n","\n","  outputs = tf.keras.layers.Dense(3, activation='softmax', kernel_initializer = tfk.initializers.GlorotUniform(SEED))(y)\n","\n","  # Connect input and output through the Model class\n","  model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","  # Compile the model\n","\n","  model.compile(loss=SparseCategoricalFocalLoss(class_weight = class_weights, gamma=2), optimizer=tfk.optimizers.Adam(learning_rate = 1e-4), metrics='accuracy')\n","\n","  return model"],"metadata":{"id":"suEaaeeocM7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#trials\n","model = build_model((224,224,1), 6)\n","model = build_model((224,224,1), 4)"],"metadata":{"id":"_7dIDKyyhm5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_model = build_model((224,224,1), 8)\n","res_model.summary()"],"metadata":{"id":"Oi4n9SNQwssS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfk.utils.plot_model(res_model)"],"metadata":{"id":"a4zA63JBqFcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del res_model"],"metadata":{"id":"yI7dd8ylJ9nV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Training"],"metadata":{"id":"xhbvF77EzCxi"}},{"cell_type":"code","source":["training_samples = int(len(train_gen)*batch_size)\n","step_size = 6*training_samples // batch_size\n","\n","clr = CyclicLR(\n","    mode='triangular',\n","    base_lr=1e-5, \n","    max_lr=1e-4,\n","    step_size= step_size)\n","\n","checkpoint_filepath = '/tmp/checkpoint'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)\n","\n","history = res_model.fit(train_gen,\n","    epochs = 20,\n","    validation_data = valid_gen,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor= 'val_accuracy', mode='max', patience=10, restore_best_weights=True), clr, model_checkpoint_callback],\n",").history"],"metadata":{"id":"7SCZzPyNxtOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The model weights (that are considered the best) are loaded into the\n","# model.\n","res_model.load_weights(checkpoint_filepath)"],"metadata":{"id":"ySv4H2fw5B7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the training\n","plt.figure(figsize=(20,5))\n","plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Category Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(20,5))\n","plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"],"metadata":{"id":"lGX8GgYHyw14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Test"],"metadata":{"id":"9YAHNT9BzFDq"}},{"cell_type":"code","source":["# Predict the test set with the CNN\n","predictions = res_model.predict(test_gen)"],"metadata":{"id":"N4NhleFHyzhQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = np.argmax(tfk.utils.to_categorical(list(test.label))[:-2], axis = -1)\n","pred = np.argmax(predictions, axis=-1)\n","target_names = ['N', 'P',' T']\n","cm = confusion_matrix(y, pred, normalize=\"true\")\n","\n","\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(y, pred)\n","precision = precision_score(y, pred, average='macro')\n","recall = recall_score(y, pred, average='macro')\n","f1 = f1_score(y, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","print(classification_report(y, pred, target_names=target_names, digits=4))\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,10))\n","sns.heatmap(cm.T, xticklabels=[0,1,2], yticklabels=[0,1,2])\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"],"metadata":{"id":"PE-HBK7gy1re"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Normalise\n","cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=list(target_names), yticklabels=list(target_names))\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.show(block=False)"],"metadata":{"id":"88ChUqm4y6vI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pb_model_dir = \"Model/denseNET_ft\"\n","h5_model = \"/gdrive/MyDrive/bestResNet.h5\"\n","\n","tf.keras.models.save_model(res_model, h5_model)"],"metadata":{"id":"HJa2rDn2pjtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##KFold crossvalidation"],"metadata":{"id":"vwToRomn1ZPy"}},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = SEED)"],"metadata":{"id":"9gvpXInOenNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(skf.split(train_val.file.to_numpy(), train_val.label.to_numpy()))"],"metadata":{"id":"PAKLe9ixilXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since the training required a lot of time, in order to perform cross-validation we saved the indices of the stratified k-fold and then trained a model at a time to avoid exceeding colab GPU time."],"metadata":{"id":"9qhxkp-JiDve"}},{"cell_type":"code","source":["for i, (train_index, valid_index) in enumerate(skf.split(train_val.file.to_numpy(), train_val.label.to_numpy())):\n","  print (i,train_index, valid_index)\n","  model_directory = '/gdrive/MyDrive/Uni/AAIB'\n","  trainname = 'train_idx' + str(i)\n","  trainname_chosen = os.path.join(model_directory, trainname)\n","  np.save(trainname_chosen, train_index)\n","  testname = 'test_idx' + str(i)\n","  testname_chosen = os.path.join(model_directory, testname)\n","  np.save(testname_chosen, valid_index)"],"metadata":{"id":"MhfSK9mQiWHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_index = np.load('/gdrive/MyDrive/Uni/AAIB/train_idx0.npy')\n","valid_index = np.load('/gdrive/MyDrive/Uni/AAIB/test_idx0.npy')"],"metadata":{"id":"0hLQhsQPLFZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainDF = train_val.filter(items= train_index, axis=0)\n","validDF = train_val.filter(items= valid_index, axis=0)\n","\n","train_gen = CustomGenerator(dataframe = trainDF, base_path = 'data/train_all_no_duplicates', batch_size = batch_size, out_shape = img_size, shuffle = True, flow_from_directory=True, preprocess_input = False, categorical = False, augment = False)\n","valid_gen = CustomGenerator(dataframe = validDF, base_path = 'data/train_all_no_duplicates', batch_size = batch_size, out_shape = img_size, shuffle = True, flow_from_directory=True, preprocess_input = False, categorical = False, augment = False)"],"metadata":{"id":"P97ISI8_LhHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["METRICS = [tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall'),\n","  ]"],"metadata":{"id":"VvvWLLJGLwdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_samples = int(len(train_gen)*batch_size)\n","step_size = 6*training_samples // batch_size\n","\n","clr = CyclicLR(\n","      mode='triangular',\n","      base_lr=1e-5, \n","      max_lr=1e-4,\n","      step_size= step_size\n","      )\n","model = build_model((224,224,3), 8)\n"," \n","epochs = 20\n","\n","history = model.fit(train_gen,\n","                    epochs=epochs,  \n","                    validation_data = valid_gen,\n","                    callbacks = [tfk.callbacks.EarlyStopping(monitor= 'val_accuracy', mode='max', patience=15, restore_best_weights=True), clr], workers =8, use_multiprocessing = True\n","                    )"],"metadata":{"id":"govwdA8CL5Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the training\n","plt.figure(figsize=(20,5))\n","plt.plot(history.history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n","plt.plot(history.history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Category Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(20,5))\n","plt.plot(history.history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n","plt.plot(history.history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()\n","\n","#prediction on test set\n","predictions = model.predict(test_gen)\n","\n","y = np.argmax(tfk.utils.to_categorical(list(test.label))[:-2], axis = -1)\n","pred = np.argmax(predictions, axis=-1)\n","target_names = ['N', 'P', 'T']\n","cm = confusion_matrix(y, pred, normalize=\"true\")\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(y, pred)\n","precision = precision_score(y, pred, average='macro')\n","recall = recall_score(y, pred, average='macro')\n","f1 = f1_score(y, pred, average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","print(classification_report(y, pred, target_names=target_names, digits=4))\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,10))\n","sns.heatmap(cm.T, xticklabels=[0,1,2], yticklabels=[0,1,2])\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()\n","\n","# Model saving\n","model_directory = '/gdrive/MyDrive/Uni/AAIB/AAIB/Davide/Kfold'\n","filename = 'resnet_kFold_0'\n","filename_chosen = os.path.join(model_directory, filename)\n","model.save(filename_chosen + '.h5', overwrite = False)\n","del model"],"metadata":{"id":"0J4quYGNkiok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# load models \n","total_model = 5\n","model_directory = '/gdrive/MyDrive/Uni/AAIB/AAIB/Davide/Resnet_models/k_fold'\n","trained_models = list()\n","for model_n in range(total_model):\n","  filename = 'resnet_kFold_' + str(model_n)\n","  filename_chosen = os.path.join(model_directory, filename)\n","  trained_models.append(load_model(filename_chosen + '.h5'))"],"metadata":{"id":"mpSUvss92up9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_stats = {}\n","plt.get_current_fig_manager().full_screen_toggle() # toggle fullscreen mode\n","\n","for idx, model in enumerate(trained_models):  \n","  predictions = model.predict(test_gen)\n","  y = np.argmax(tfk.utils.to_categorical(list(test.label))[:-2], axis = -1)\n","  pred = np.argmax(predictions, axis=-1)\n","  target_names = ['N', 'P', 'T']\n","  cm = confusion_matrix(y, pred, normalize=\"true\")\n","\n","\n","  # Compute the classification metrics\n","  accuracy = accuracy_score(y, pred)\n","  precision = precision_score(y, pred, average='macro')\n","  recall = recall_score(y, pred, average='macro')\n","  f1 = f1_score(y, pred, average='macro')\n","\n","\n","  validation_stats['fold_' + str(idx+1) ] = {\n","      'accuracy' : accuracy,\n","      'precision' :precision,\n","      'recall' :recall,\n","      'f1' :f1,\n","      'classification_report' :classification_report(y, pred, target_names=target_names, digits=4, output_dict = True)}\n","\n","\n","  print('Accuracy:',accuracy.round(4))\n","  print('Precision:',precision.round(4))\n","  print('Recall:',recall.round(4))\n","  print('F1:',f1.round(4))\n","  print(classification_report(y, pred, target_names=target_names, digits=4))\n","  # Plot the confusion matrix\n","  plt.figure(figsize=(10,10))\n","  hm = sns.heatmap(cm.T, xticklabels=[0,1,2], yticklabels=[0,1,2])\n","  plt.xlabel('True labels')\n","  plt.ylabel('Predicted labels')\n","  plt.show()\n","\n","\n","with open('/gdrive/MyDrive/Uni/AAIB/AAIB/Davide/Kfold/test_stats.json' , 'w') as fp:\n","    json.dump(validation_stats, fp)"],"metadata":{"id":"whZ_Dwp1qRd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = []\n","\n","for idx, svm_model in enumerate(trained_models):  \n","  predictions = svm_model.predict(test_gen)\n","  y = np.argmax(tfk.utils.to_categorical(list(test.label))[:-2], axis = -1)\n","  pred = np.argmax(predictions, axis=-1)\n","\n","  preds.append(pred)"],"metadata":{"id":"YS-hkIGtrWrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds_mv = scipy.stats.mode(preds, axis=0)[0][0]"],"metadata":{"id":"4ntHeGJGsKWk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = np.argmax(tfk.utils.to_categorical(list(test.label))[:-2], axis = -1)\n","pred = preds_mv\n","target_names = ['N', 'P', 'T']\n","cm = confusion_matrix(y, pred, normalize=\"true\")\n","\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(y, pred)\n","precision = precision_score(y, pred, average='macro')\n","recall = recall_score(y, pred, average='macro')\n","f1 = f1_score(y, pred, average='macro')\n","\n","test_stats = {\n","      'accuracy' : accuracy,\n","      'precision' :precision,\n","      'recall' :recall,\n","      'f1' :f1,\n","      'classification_report' :classification_report(y, pred, target_names=target_names, digits=4, output_dict = True)}\n","\n","\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","print(classification_report(y, pred, target_names=target_names, digits=4))\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,10))\n","hm = sns.heatmap(cm.T, xticklabels=[0,1,2], yticklabels=[0,1,2])\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()\n","\n","hm.get_figure().savefig(\"ensemble_cm.pdf\")\n","\n","with open('test_stats_ensemble.json' , 'w') as fp:\n","    json.dump(test_stats, fp)"],"metadata":{"id":"SZlpeR-rsNXW"},"execution_count":null,"outputs":[]}]}